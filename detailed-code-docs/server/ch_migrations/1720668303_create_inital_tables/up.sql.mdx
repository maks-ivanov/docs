---
title: "up.sql"
---

## High-level description
This SQL script creates several tables in a ClickHouse database for storing various types of data related to datasets, search queries, cluster topics, and recommendations. The tables are designed to efficiently store and query data with specific partitioning, ordering, and TTL (Time To Live) settings.

## Table of contents
- CREATE TABLE dataset_events
- CREATE TABLE search_queries
- CREATE TABLE cluster_topics
- CREATE TABLE search_cluster_memberships
- CREATE TABLE rag_queries
- CREATE TABLE recommendations

## Code Structure
The script consists of six `CREATE TABLE` statements, each defining a table with specific columns, data types, and table engine settings. The tables are designed to work together to store related information about datasets, searches, and recommendations.

## Symbols

### CREATE TABLE dataset_events
#### Description
Creates a table to store events related to datasets.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| id | UUID | Unique identifier for the event |
| created_at | DateTime | Timestamp of the event creation |
| dataset_id | UUID | Identifier of the associated dataset |
| event_type | String | Type of the event |
| event_data | String | Data associated with the event |

#### Internal Logic
- Uses MergeTree engine for efficient data storage and retrieval
- Orders data by dataset_id, created_at, event_type, and id
- Partitions data by month of creation and dataset_id
- Sets a TTL of 30 days based on the created_at field

### CREATE TABLE search_queries
#### Description
Creates a table to store information about search queries.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| id | UUID | Unique identifier for the search query |
| search_type | String | Type of search performed |
| query | String | The search query string |
| request_params | String | Parameters of the search request |
| latency | Float32 | Search latency in seconds |
| top_score | Float32 | Highest score of search results |
| results | Array(String) | Array of search result identifiers |
| query_vector | Array(Float32) | Vector representation of the query |
| dataset_id | UUID | Identifier of the associated dataset |
| created_at | DateTime | Timestamp of the search query |
| is_duplicate | UInt8 | Flag to indicate if the query is a duplicate |

#### Internal Logic
- Uses ReplacingMergeTree engine with is_duplicate field for deduplication
- Orders data by dataset_id, created_at, top_score, latency, and id
- Partitions data by month of creation and dataset_id
- Sets a TTL of 30 days based on the created_at field

### CREATE TABLE cluster_topics
#### Description
Creates a table to store information about cluster topics.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| id | UUID | Unique identifier for the cluster topic |
| dataset_id | UUID | Identifier of the associated dataset |
| topic | String | The topic of the cluster |
| density | Int32 | Density of the cluster |
| avg_score | Float32 | Average score of the cluster |
| created_at | DateTime | Timestamp of the cluster topic creation |

#### Internal Logic
- Uses MergeTree engine for efficient data storage and retrieval
- Orders data by dataset_id and id
- Partitions data by dataset_id

### CREATE TABLE search_cluster_memberships
#### Description
Creates a table to store relationships between search queries and clusters.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| id | UUID | Unique identifier for the membership |
| search_id | UUID | Identifier of the associated search query |
| cluster_id | UUID | Identifier of the associated cluster |
| distance_to_centroid | Float32 | Distance of the search query to the cluster centroid |

#### Internal Logic
- Uses MergeTree engine for efficient data storage and retrieval
- Orders data by id

### CREATE TABLE rag_queries
#### Description
Creates a table to store information about RAG (Retrieval-Augmented Generation) queries.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| id | UUID | Unique identifier for the RAG query |
| rag_type | String | Type of RAG query |
| user_message | String | The user's input message |
| search_id | UUID | Identifier of the associated search query |
| results | Array(String) | Array of result identifiers |
| llm_response | String | Response generated by the language model |
| dataset_id | UUID | Identifier of the associated dataset |
| created_at | DateTime | Timestamp of the RAG query |

#### Internal Logic
- Uses MergeTree engine for efficient data storage and retrieval
- Orders data by id and created_at
- Partitions data by month of creation and dataset_id
- Sets a TTL of 30 days based on the created_at field

### CREATE TABLE recommendations
#### Description
Creates a table to store recommendation data.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| id | UUID | Unique identifier for the recommendation |
| recommendation_type | String | Type of recommendation |
| positive_ids | Array(String) | Array of positively rated item identifiers |
| negative_ids | Array(String) | Array of negatively rated item identifiers |
| positive_tracking_ids | Array(String) | Array of positively rated tracking identifiers |
| negative_tracking_ids | Array(String) | Array of negatively rated tracking identifiers |
| request_params | String | Parameters of the recommendation request |
| results | Array(String) | Array of recommended item identifiers |
| top_score | Float32 | Highest score of recommended items |
| dataset_id | UUID | Identifier of the associated dataset |
| created_at | DateTime | Timestamp of the recommendation |

#### Internal Logic
- Uses MergeTree engine for efficient data storage and retrieval
- Orders data by id and created_at
- Partitions data by month of creation and dataset_id
- Sets a TTL of 30 days based on the created_at field

## Dependencies
| Dependency | Purpose |
|:-----------|:--------|
| ClickHouse | Database system used for storing and querying the data |

## Future Improvements
1. Consider adding indexes on frequently queried columns to improve query performance.
2. Evaluate the need for additional tables or columns as the system evolves.
3. Review and adjust TTL settings based on actual data retention requirements.
4. Consider implementing data compression techniques for large string columns to optimize storage.
5. Explore the use of materialized views for frequently accessed aggregated data.