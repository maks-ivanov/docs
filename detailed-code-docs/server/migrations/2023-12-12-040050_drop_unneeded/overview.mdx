---
title: "Overview"
---

## High-level description
This directory contains SQL migration scripts for a database schema update. The migration involves removing several database objects that are no longer needed and provides a way to revert these changes if necessary. The scripts are designed to clean up the database schema by dropping unused tables, columns, triggers, and functions.

## What does it do?
The migration performs the following actions:

1. In the "up" migration:
   - Removes the `card_metadata_tsvector` column from the `card_metadata` table
   - Drops the `invitations` table
   - Drops the `password_resets` table
   - Removes the `update_tsvector_trigger` trigger from the `card_metadata` table
   - Drops the `update_tsvector()` function

2. In the "down" migration (reverting the changes):
   - Recreates the `invitations` table
   - Recreates the `password_resets` table
   - Adds back the `card_metadata_tsvector` column to the `card_metadata` table
   - Recreates the `update_tsvector()` function
   - Recreates the `update_tsvector_trigger` trigger

These changes simplify the database schema by removing unused elements, potentially improving performance and maintainability. The "down" migration ensures that these changes can be rolled back if needed.

## Key Files

1. `up.sql`:
   This file contains the SQL commands to remove the unnecessary database objects. It's responsible for cleaning up the schema by dropping tables, columns, triggers, and functions that are no longer needed.

2. `down.sql`:
   This file contains the SQL commands to revert the changes made by the `up.sql` script. It recreates the dropped tables and functions, allowing for a rollback of the migration if necessary.

## Configuration
The migration scripts use SQL commands that are compatible with PostgreSQL. They rely on the following database objects:

1. `card_metadata` table
2. `invitations` table (to be dropped)
3. `password_resets` table (to be dropped)
4. `update_tsvector_trigger` (to be dropped)
5. `update_tsvector()` function (to be dropped)

The scripts use `IF EXISTS` clauses to ensure that the operations are safe to run even if the objects have already been removed or don't exist.

## Code Examples

Here's an example of how the `up.sql` script removes the `card_metadata_tsvector` column:

```sql
ALTER TABLE card_metadata DROP COLUMN IF EXISTS card_metadata_tsvector;
```

And here's how the `down.sql` script recreates the `invitations` table:

```sql
CREATE TABLE IF NOT EXISTS invitations (
    id UUID PRIMARY KEY,
    email VARCHAR(100) NOT NULL,
    expires_at TIMESTAMP NOT NULL,
    created_at TIMESTAMP NOT NULL,
    updated_at TIMESTAMP NOT NULL
);
```

These examples demonstrate the careful approach taken to ensure that the migration can be safely applied and reverted.

## Future Improvements

1. Add comments to the migration scripts explaining why specific database objects are being removed or recreated. This would improve maintainability and help future developers understand the reasoning behind these changes.

2. Consider adding indexes on frequently queried columns in the `invitations` and `password_resets` tables when recreating them in the `down.sql` script. This could improve query performance if these tables are reintroduced.

3. Evaluate the need for additional constraints (e.g., CHECK constraints) on the `expires_at` columns in the `invitations` and `password_resets` tables to ensure they are set to future dates.

4. If the removed `card_metadata_tsvector` column and associated trigger were used for full-text search functionality, consider implementing an alternative solution or explaining why this functionality is no longer needed.

5. Ensure that any application code relying on the removed database objects is updated accordingly to prevent errors after applying the migration.

6. Consider splitting this migration into smaller, more focused migrations if the changes are not strictly related. This could make it easier to manage and revert specific parts of the schema changes if needed.

By implementing these improvements, the migration process could become more robust, maintainable, and aligned with best practices in database schema management.